{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap Reduction Experiment  \n",
    "\n",
    "## Objective  \n",
    "This experiment aims to determine the **minimum overlap required** to achieve accurate **3D alignment and reconstruction** while using fewer images.  \n",
    "\n",
    "### Dataset Selection  \n",
    "- A set of images of the **same building** is selected, captured with **high initial overlap** (e.g., **80% frontal, 60% lateral**).  \n",
    "- Preferably, the dataset should feature a **complex structure** (facades, corners, textured roofs) to challenge the reconstruction process.  \n",
    "\n",
    "### Creating Subsets with Different Overlaps  \n",
    "Multiple subsets are generated by **progressively reducing** the overlap:  \n",
    "\n",
    "| Dataset  | Frontal Overlap | Lateral Overlap | Number of Images |\n",
    "|----------|----------------|-----------------|------------------|\n",
    "| **Full Dataset** | 80% | 60% | 100% (Baseline) |\n",
    "| **Set 1** | 70% | 50% | ðŸ”½ -X% |\n",
    "| **Set 2** | 60% | 40% | ðŸ”½ -Y% |\n",
    "| **Set 3** | 50% | 30% | ðŸ”½ -Z% |\n",
    "\n",
    "**DeepPruneâ€™s CNN** is applied to select the most informative images, which are then compared with **randomly selected subsets**.  \n",
    "\n",
    "### Processing in Reality Capture  \n",
    "For each subset:  \n",
    "1. The images are loaded into **Reality Capture**.  \n",
    "2. The **image alignment** process is executed, recording:  \n",
    "   - Number of aligned images  \n",
    "   - Number of detected key points  \n",
    "   - Point cloud quality  \n",
    "3. The **3D mesh** is generated and evaluated based on:  \n",
    "   - Presence of **geometric errors**  \n",
    "   - Presence of **gaps or distortions**  \n",
    "   - **Processing time** and **memory usage**  \n",
    "\n",
    "### Comparison and Analysis  \n",
    "The results are analyzed through visual comparisons:  \n",
    "- **Number of images vs. Reconstruction accuracy**  \n",
    "- **Processing time vs. Number of images**  \n",
    "- **Quality loss in the mesh with lower overlap**  \n",
    "\n",
    "### Expected Outcome  \n",
    "The experiment seeks to identify the **optimal point** where the number of images can be **reduced** **without significantly compromising accuracy**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary Script\n",
    "Tasks:\n",
    "- Extracts visual features from images using ResNet50 to select the most informative ones.\n",
    "- Filters out redundant images using K-Means clustering, optimizing the selection.\n",
    "- Generates subsets with different levels of overlap (80%, 70%, 60%, 50%).\n",
    "- Copies the selected images to folders ready for processing in Reality Capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import exifread\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "# --------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------\n",
    "BASE_FOLDER = \"path_to_photogrammetry_images\"  # Path to original images\n",
    "OUTPUT_FOLDER = \"path_to_selected_images\"  # Path to save subsets\n",
    "\n",
    "# Define overlap levels to test\n",
    "OVERLAP_LEVELS = {\"80_60\": (80, 60), \"70_50\": (70, 50), \"60_40\": (60, 40), \"50_30\": (50, 30)}\n",
    "\n",
    "# --------------------------\n",
    "# FUNCTION TO READ EXIF METADATA\n",
    "# --------------------------\n",
    "def get_exif_metadata(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        tags = exifread.process_file(f, stop_tag='EXIF')\n",
    "    gps_data = {}\n",
    "    if 'GPS GPSLatitude' in tags and 'GPS GPSLongitude' in tags:\n",
    "        lat = tags['GPS GPSLatitude'].values\n",
    "        lon = tags['GPS GPSLongitude'].values\n",
    "        gps_data = {'latitude': lat, 'longitude': lon}\n",
    "    return gps_data\n",
    "\n",
    "# --------------------------\n",
    "# FUNCTION TO EXTRACT FEATURES WITH CNN (RESNET50)\n",
    "# --------------------------\n",
    "def extract_features(image_path, model, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().numpy()\n",
    "\n",
    "# --------------------------\n",
    "# IMAGE SELECTION BASED ON KEY INFORMATION (DeepPrune)\n",
    "# --------------------------\n",
    "def select_optimal_images(image_folder, overlap_percentage, model, transform):\n",
    "    images = sorted(os.listdir(image_folder))\n",
    "    feature_vectors = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for img in images:\n",
    "        img_path = os.path.join(image_folder, img)\n",
    "        features = extract_features(img_path, model, transform)\n",
    "        feature_vectors.append(features)\n",
    "        image_paths.append(img_path)\n",
    "    \n",
    "    feature_vectors = np.array(feature_vectors)\n",
    "    \n",
    "    # Group similar images with KMeans to avoid redundancy\n",
    "    n_clusters = max(1, len(images) * overlap_percentage // 100)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(feature_vectors)\n",
    "    \n",
    "    # Select one representative image per cluster\n",
    "    selected_images = []\n",
    "    for i in range(n_clusters):\n",
    "        idx = np.where(labels == i)[0][0]\n",
    "        selected_images.append(image_paths[idx])\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "# --------------------------\n",
    "# MAIN PROCESSING\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load pre-trained model (ResNet50 without final layer)\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "    resnet50.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    for level, (front_overlap, side_overlap) in OVERLAP_LEVELS.items():\n",
    "        print(f\"Processing overlap {level}...\")\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, level)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        selected_images = select_optimal_images(BASE_FOLDER, front_overlap, resnet50, transform)\n",
    "        \n",
    "        # Copy selected images to the new folder\n",
    "        for img in selected_images:\n",
    "            shutil.copy(img, output_path)\n",
    "        \n",
    "        print(f\"{len(selected_images)} images selected and saved in {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
